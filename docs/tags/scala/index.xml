<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Scala on lust.dev</title><link>https://lust.dev/tags/scala/</link><description>Recent content in Scala on lust.dev</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Joseph Lust</copyright><lastBuildDate>Sun, 08 May 2016 00:00:00 +0000</lastBuildDate><atom:link href="https://lust.dev/tags/scala/index.xml" rel="self" type="application/rss+xml"/><item><title>Modulo Operator Performance Impact</title><link>https://lust.dev/2016/05/08/modulo-operator-performance-impact/</link><pubDate>Sun, 08 May 2016 00:00:00 +0000</pubDate><guid>https://lust.dev/2016/05/08/modulo-operator-performance-impact/</guid><description>My textbooks used modulo, yet my boss told me not to. Where had I gone wrong?</description></item><item><title>Dangers of the Unit Type Parameter</title><link>https://lust.dev/2016/04/12/dangers-of-unit-type-parameter/</link><pubDate>Tue, 12 Apr 2016 00:00:00 +0000</pubDate><guid>https://lust.dev/2016/04/12/dangers-of-unit-type-parameter/</guid><description>Confusing misuses of Unit and the loss of type checking.</description></item><item><title>Home Cooked Apache Spark</title><link>https://lust.dev/2016/01/07/home-cooked-apache-spark/</link><pubDate>Thu, 07 Jan 2016 00:00:00 +0000</pubDate><guid>https://lust.dev/2016/01/07/home-cooked-apache-spark/</guid><description>We use Apache Spark for various applications at my job, but Spark is still relatively unstable, as evidenced by the project&amp;rsquo;s 11K+ pull requests. To maintain developer velocity, we regularly patch show stopper bugs in the Spark source. The process is simple.
Install JDK 6, which is required for PySpark (or you&amp;rsquo;ll get a lengthy warning). Use the oracle-java8-set-default package to switch between Java 6 and 8, or set JAVA_HOME.</description></item><item><title>Remote Debugging Apache Spark Clusters</title><link>https://lust.dev/2016/01/01/remote-debugging-apache-spark-clusters/</link><pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate><guid>https://lust.dev/2016/01/01/remote-debugging-apache-spark-clusters/</guid><description>Debugging Apache Spark can be tricky. Sure, everything works on your --master local[4] cluster, but not when run on a real cluster. In these cases, you need to drop to a debug breakpoint in the running cluster.
Get Debugger Listening Simply update the launch args wherever you start Spark like so. Note: SPARK_JAVA_OPTS won&amp;rsquo;t do the trick.
export SPARK_WORKER_OPTS=&amp;quot;-Xdebug -Xrunjdwp:server=y,transport=dt_socket,address=4000,suspend=n&amp;quot; export SPARK_MASTER_OPTS=&amp;quot;-Xdebug -Xrunjdwp:server=y,transport=dt_socket,address=4000,suspend=n&amp;quot; /opt/spark/sbin/start-master.sh Open an SSH tunnel to your remote cluster machine, mapping localhost:4000 to spark-master.</description></item></channel></rss>